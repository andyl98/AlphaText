{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andyl\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import DataCollatorForSeq2Seq, AdamWeightDecay, \\\n",
    "    TFT5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\" Use tokenizer to preprocess data. \"\"\"\n",
    "    \n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    prefix = \"summarize: \"\n",
    "\n",
    "    inputs = [prefix + doc for doc in examples[\"article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"highlights\"], max_length=80, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def download_and_preprocess_data():\n",
    "    \"\"\" Load dataset from HuggingFace and preprocess. \"\"\"\n",
    "    \n",
    "    news_ds = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test\")\n",
    "\n",
    "    # Tokenized using preprocess_function\n",
    "    tokenized_news = news_ds.map(preprocess_function, batched=True)\n",
    "\n",
    "    return tokenized_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5_small_news.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour, please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "optimizer = AdamWeightDecay(\n",
    "    learning_rate=2e-5, \n",
    "    weight_decay_rate=0.01\n",
    ")\n",
    "\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(\"t5_small_news\")\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, \n",
    "    model=model, \n",
    "    return_tensors=\"tf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (C:\\Users\\andyl\\.cache\\huggingface\\datasets\\cnn_dailymail\\3.0.0\\3.0.0\\3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n",
      "Loading cached processed dataset at C:\\Users\\andyl\\.cache\\huggingface\\datasets\\cnn_dailymail\\3.0.0\\3.0.0\\3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234\\cache-55793dd6c08d73ff.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 11490\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_news = download_and_preprocess_data()\n",
    "tokenized_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tokenized_news.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=4,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(metric, pred, actual):\n",
    "    \"\"\" Compute the model's rouge performance on an instance. \"\"\"\n",
    "\n",
    "    metric.add(predictions=pred, references=actual)\n",
    "    final_score = metric.compute()\n",
    "    \n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 100\n",
      "Round: 200\n",
      "Round: 300\n",
      "Round: 400\n",
      "Round: 500\n",
      "Round: 600\n",
      "Round: 700\n",
      "Round: 800\n",
      "Round: 900\n",
      "Round: 1000\n",
      "Round: 1100\n",
      "Round: 1200\n",
      "Round: 1300\n",
      "Round: 1400\n",
      "Round: 1500\n",
      "Round: 1600\n",
      "Round: 1700\n",
      "Round: 1800\n",
      "Round: 1900\n",
      "Round: 2000\n",
      "Round: 2100\n",
      "Round: 2200\n",
      "Round: 2300\n",
      "Round: 2400\n",
      "Round: 2500\n",
      "Round: 2600\n",
      "Round: 2700\n",
      "Round: 2800\n",
      "Round: 2900\n",
      "Round: 3000\n",
      "Round: 3100\n",
      "Round: 3200\n",
      "Round: 3300\n",
      "Round: 3400\n",
      "Round: 3500\n",
      "Round: 3600\n",
      "Round: 3700\n",
      "Round: 3800\n",
      "Round: 3900\n",
      "Round: 4000\n",
      "Round: 4100\n",
      "Round: 4200\n",
      "Round: 4300\n",
      "Round: 4400\n",
      "Round: 4500\n",
      "Round: 4600\n",
      "Round: 4700\n",
      "Round: 4800\n",
      "Round: 4900\n",
      "Round: 5000\n",
      "Round: 5100\n",
      "Round: 5200\n",
      "Round: 5300\n",
      "Round: 5400\n",
      "Round: 5500\n",
      "Round: 5600\n",
      "Round: 5700\n",
      "Round: 5800\n",
      "Round: 5900\n",
      "Round: 6000\n",
      "Round: 6100\n",
      "Round: 6200\n",
      "Round: 6300\n",
      "Round: 6400\n",
      "Round: 6500\n",
      "Round: 6600\n",
      "Round: 6700\n",
      "Round: 6800\n",
      "Round: 6900\n",
      "Round: 7000\n",
      "Round: 7100\n",
      "Round: 7200\n",
      "Round: 7300\n",
      "Round: 7400\n",
      "Round: 7500\n",
      "Round: 7600\n",
      "Round: 7700\n",
      "Round: 7800\n",
      "Round: 7900\n",
      "Round: 8000\n",
      "Round: 8100\n",
      "Round: 8200\n",
      "Round: 8300\n",
      "Round: 8400\n",
      "Round: 8500\n",
      "Round: 8600\n",
      "Round: 8700\n",
      "Round: 8800\n",
      "Round: 8900\n",
      "Round: 9000\n",
      "Round: 9100\n",
      "Round: 9200\n",
      "Round: 9300\n",
      "Round: 9400\n",
      "Round: 9500\n",
      "Round: 9600\n",
      "Round: 9700\n",
      "Round: 9800\n",
      "Round: 9900\n",
      "Round: 10000\n",
      "Round: 10100\n",
      "Round: 10200\n",
      "Round: 10300\n",
      "Round: 10400\n",
      "Round: 10500\n",
      "Round: 10600\n",
      "Round: 10700\n",
      "Round: 10800\n",
      "Round: 10900\n",
      "Round: 11000\n",
      "Round: 11100\n",
      "Round: 11200\n",
      "Round: 11300\n",
      "Round: 11400\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric('rouge')\n",
    "result = [[] for x in range(3)]\n",
    "\n",
    "cnt = 0\n",
    "for item in test_ds:\n",
    "    article = item['input_ids']\n",
    "    actual = item['labels']\n",
    "    \n",
    "    pred = model.generate(\n",
    "        do_sample=True,\n",
    "        input_ids=article,\n",
    "        # min_length=56,\n",
    "        max_length=80,\n",
    "        temperature=0.8, \n",
    "        top_k=45,\n",
    "        no_repeat_ngram_size=3,\n",
    "        num_beams=5,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    rouge_score = compute_metrics(metric, pred, actual)\n",
    "    rouge1 = 100 * rouge_score['rouge1'][1][2]\n",
    "    rouge2 = 100 * rouge_score['rouge2'][1][2]\n",
    "    rougeL = 100 * rouge_score['rougeL'][1][2]\n",
    "\n",
    "    cnt += 1 \n",
    "    if cnt % 25 == 0:\n",
    "        print(f'Round: {cnt * 4}')\n",
    "\n",
    "    result[0].append(rouge1)\n",
    "    result[1].append(rouge2)\n",
    "    result[2].append(rougeL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>RougeL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.043478</td>\n",
       "      <td>21.834061</td>\n",
       "      <td>29.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.362832</td>\n",
       "      <td>20.444444</td>\n",
       "      <td>25.663717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.849673</td>\n",
       "      <td>20.983607</td>\n",
       "      <td>27.450980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.478261</td>\n",
       "      <td>20.087336</td>\n",
       "      <td>29.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.352941</td>\n",
       "      <td>11.475410</td>\n",
       "      <td>18.627451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>54.375000</td>\n",
       "      <td>33.855799</td>\n",
       "      <td>39.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>25.391850</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>54.375000</td>\n",
       "      <td>29.153605</td>\n",
       "      <td>31.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>35.312500</td>\n",
       "      <td>11.285266</td>\n",
       "      <td>19.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>40.625000</td>\n",
       "      <td>23.270440</td>\n",
       "      <td>26.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2873 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Rouge1     Rouge2     RougeL\n",
       "0     43.043478  21.834061  29.130435\n",
       "1     43.362832  20.444444  25.663717\n",
       "2     40.849673  20.983607  27.450980\n",
       "3     43.478261  20.087336  29.565217\n",
       "4     32.352941  11.475410  18.627451\n",
       "...         ...        ...        ...\n",
       "2868  54.375000  33.855799  39.375000\n",
       "2869  52.500000  25.391850  30.000000\n",
       "2870  54.375000  29.153605  31.875000\n",
       "2871  35.312500  11.285266  19.375000\n",
       "2872  40.625000  23.270440  26.875000\n",
       "\n",
       "[2873 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(data = np.array(result).T, columns = ['Rouge1','Rouge2','RougeL'])\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>RougeL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2873.000000</td>\n",
       "      <td>2873.000000</td>\n",
       "      <td>2873.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48.644851</td>\n",
       "      <td>25.545884</td>\n",
       "      <td>30.806560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.285275</td>\n",
       "      <td>6.257816</td>\n",
       "      <td>5.866729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>23.553719</td>\n",
       "      <td>6.639004</td>\n",
       "      <td>12.809917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>44.921875</td>\n",
       "      <td>21.316614</td>\n",
       "      <td>26.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.750000</td>\n",
       "      <td>25.078370</td>\n",
       "      <td>30.254777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52.812500</td>\n",
       "      <td>29.153605</td>\n",
       "      <td>34.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>69.687500</td>\n",
       "      <td>50.156740</td>\n",
       "      <td>54.687500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rouge1       Rouge2       RougeL\n",
       "count  2873.000000  2873.000000  2873.000000\n",
       "mean     48.644851    25.545884    30.806560\n",
       "std       6.285275     6.257816     5.866729\n",
       "min      23.553719     6.639004    12.809917\n",
       "25%      44.921875    21.316614    26.875000\n",
       "50%      48.750000    25.078370    30.254777\n",
       "75%      52.812500    29.153605    34.375000\n",
       "max      69.687500    50.156740    54.687500"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play around with text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\" \n",
    "NEW DELHI, India (CNN) -- A high court in northern India on Friday acquitted a wealthy businessman facing the death sentence for the killing of a teen in a case dubbed \"the house of horrors.\"\n",
    "Moninder Singh Pandher was sentenced to death by a lower court in February.\n",
    "The teen was one of 19 victims -- children and young women -- in one of the most gruesome serial killings in India in recent years.\n",
    "The Allahabad high court has acquitted Moninder Singh Pandher, his lawyer Sikandar B. Kochar told CNN.\n",
    "Pandher and his domestic employee Surinder Koli were sentenced to death in February by a lower court for the rape and murder of the 14-year-old.\n",
    "The high court upheld Koli's death sentence, Kochar said.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original =  \n",
      "NEW DELHI, India (CNN) -- A high court in northern India on Friday acquitted a wealthy businessman facing the death sentence for the killing of a teen in a case dubbed \"the house of horrors.\"\n",
      "Moninder Singh Pandher was sentenced to death by a lower court in February.\n",
      "The teen was one of 19 victims -- children and young women -- in one of the most gruesome serial killings in India in recent years.\n",
      "The Allahabad high court has acquitted Moninder Singh Pandher, his lawyer Sikandar B. Kochar told CNN.\n",
      "Pandher and his domestic employee Surinder Koli were sentenced to death in February by a lower court for the rape and murder of the 14-year-old.\n",
      "The high court upheld Koli's death sentence, Kochar said.\n",
      "\n",
      "\n",
      "pred = Moninder Singh Pandher was one of 19 victims in one of most gruesome serial killings in India. Pandhe and his domestic employee Surinder Koli were sentenced to death in February. High court upheld Koli's death sentence, lawyer says.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "tokenized_input = tokenizer(\"summarize: \" + article, max_length=1024, truncation=True, return_tensors='tf')\n",
    "\n",
    "pred = model.generate(\n",
    "    do_sample=True,\n",
    "    input_ids=tokenized_input['input_ids'],\n",
    "    min_length=56,\n",
    "    max_length=128,\n",
    "    temperature=0.8, \n",
    "    top_k=45,\n",
    "    no_repeat_ngram_size=3,\n",
    "    num_beams=5,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "pred_sentence = tokenizer.decode(pred[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"original = {article}\\n\")\n",
    "print(f\"pred = {pred_sentence}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd29c989d3089037e826ab9488a38a2a82509ddcead8163e9902bc713a43fdfa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
